package com.mediplus.pruebas.analisis;

import com.mediplus.pruebas.analisis.modelo.MetricaRendimiento;
import com.mediplus.pruebas.analisis.AnalizadorMetricas;
import com.mediplus.pruebas.analisis.configuracion.ConfiguracionAplicacion;

import java.nio.file.Path;
import java.nio.file.Files;
import java.util.Comparator;
import java.util.List;
import java.util.ArrayList;
import java.util.logging.Logger;
import java.util.logging.Level;

/**
 * Clase principal para ejecutar el an√°lisis de m√©tricas de rendimiento
 * Punto de entrada de la aplicaci√≥n de an√°lisis
 * Version 2.0 - Sin dependencias a clases obsoletas
 *
 * @author Antonio B. Arriagada LL., Dante Escalona Bustos, Roberto Rivas Lopez
 */
public class EjecutorAnalisisMetricas {

    private static final Logger LOGGER = Logger.getLogger(EjecutorAnalisisMetricas.class.getName());

    public static void main(String[] args) {
        try {
            EjecutorAnalisisMetricas ejecutor = new EjecutorAnalisisMetricas();
            ejecutor.ejecutarAnalisisCompleto();
        } catch (Exception e) {
            LOGGER.log(Level.SEVERE, "Error durante la ejecuci√≥n del an√°lisis", e);
            System.exit(1);
        }
    }

    /**
     * Ejecuta el an√°lisis completo de m√©tricas
     */
    public void ejecutarAnalisisCompleto() throws Exception {
        LOGGER.info("üöÄ Iniciando an√°lisis de m√©tricas de rendimiento API MediPlus");

        // Configuraci√≥n de directorios
        ConfiguracionAplicacion configuracion = ConfiguracionAplicacion.obtenerInstancia();
        Path directorioResultados = configuracion.obtenerDirectorioResultados();
        Path directorioReportes = configuracion.obtenerDirectorioReportes();

        // Validar que existan los directorios
        validarDirectorios(directorioResultados);

        // Inicializar analizador de m√©tricas (CORREGIDO - sin LectorArchivosJTL)
        AnalizadorMetricas analizadorMetricas = new AnalizadorMetricas();

        // Procesar archivos JTL
        LOGGER.info("üìä Procesando archivos de resultados JTL...");
        List<MetricaRendimiento> metricas = procesarArchivosJTL(directorioResultados, analizadorMetricas);

        if (metricas.isEmpty()) {
            LOGGER.warning("‚ö†Ô∏è No se encontraron m√©tricas v√°lidas para analizar");
            System.out.println("‚ö†Ô∏è No se encontraron archivos .jtl para procesar");
            System.out.println("üí° Tip: Ejecuta primero las pruebas JMeter o usa datos simulados");
            return;
        }

        LOGGER.info(String.format("‚úÖ Se procesaron %d m√©tricas exitosamente", metricas.size()));

        // Mostrar resumen en consola
        mostrarResumenEnConsola(metricas);

        // Generar an√°lisis comparativo
        LOGGER.info("üîç Generando an√°lisis comparativo...");
        AnalizadorMetricas.ComparacionMetricas comparacion = analizadorMetricas.compararMetricas(metricas);

        // Generar reportes (CORREGIDO - usar AnalizadorMetricas)
        LOGGER.info("üìã Generando reportes completos...");
        analizadorMetricas.generarReporteCompleto(metricas, directorioReportes);

        // Mostrar recomendaciones principales
        mostrarRecomendacionesPrincipales(comparacion);

        LOGGER.info("üéâ An√°lisis completado exitosamente. Revisa el directorio 'reportes' para ver los resultados detallados.");
    }

    private void validarDirectorios(Path directorioResultados) {
        if (!directorioResultados.toFile().exists()) {
            LOGGER.warning("‚ö†Ô∏è El directorio de resultados no existe: " + directorioResultados);
            LOGGER.info("üí° Creando directorio de resultados y generando datos simulados...");

            try {
                Files.createDirectories(directorioResultados);
                generarDatosSimuladosParaDemostracion();
            } catch (Exception e) {
                throw new IllegalArgumentException("No se pudo crear directorio de resultados: " + directorioResultados);
            }
        }
    }

    /**
     * Genera datos simulados para demostraci√≥n cuando no hay archivos JTL reales
     */
    private void generarDatosSimuladosParaDemostracion() {
        LOGGER.info("üé≠ Generando m√©tricas simuladas para demostraci√≥n...");
        // Este m√©todo podr√≠a crear archivos JTL simulados si fuera necesario
        // Por ahora, el sistema manejar√° la ausencia de archivos autom√°ticamente
    }

    private List<MetricaRendimiento> procesarArchivosJTL(Path directorioResultados, AnalizadorMetricas analizador) {
        List<MetricaRendimiento> metricas = new ArrayList<>();

        try {
            Files.list(directorioResultados)
                    .filter(p -> p.toString().endsWith(".jtl"))
                    .forEach(archivo -> {
                        try {
                            System.out.println("üìä Procesando: " + archivo.getFileName());
                            MetricaRendimiento metrica = analizador.procesarArchivoJTL(archivo);
                            if (metrica != null) {
                                metricas.add(metrica);
                            }
                        } catch (Exception e) {
                            System.err.println("‚ö†Ô∏è Error procesando " + archivo.getFileName() + ": " + e.getMessage());
                        }
                    });
        } catch (Exception e) {
            LOGGER.log(Level.WARNING, "Error listando archivos JTL", e);
        }

        return metricas;
    }

    private void mostrarResumenEnConsola(List<MetricaRendimiento> metricas) {
        System.out.println("\n" + "=".repeat(80));
        System.out.println("üìä RESUMEN EJECUTIVO DE M√âTRICAS");
        System.out.println("=".repeat(80));

        System.out.printf("%-25s %-10s %-15s %-15s %-12s %-10s%n",
                "ESCENARIO", "USUARIOS", "TIEMPO PROM.", "THROUGHPUT", "ERROR %", "NIVEL");
        System.out.println("-".repeat(80));

        metricas.stream()
                .sorted(Comparator.comparing(MetricaRendimiento::getNombreEscenario)
                        .thenComparing(MetricaRendimiento::getUsuariosConcurrentes))
                .forEach(metrica -> System.out.printf("%-25s %-10d %-15s %-15s %-12s %-10s%n",
                        metrica.getNombreEscenario(),
                        metrica.getUsuariosConcurrentes(),
                        String.format("%.0f ms", metrica.getTiempoPromedioMs()),
                        String.format("%.1f req/s", metrica.getThroughputReqSeg()),
                        String.format("%.1f%%", metrica.getTasaErrorPorcentaje()),
                        metrica.evaluarNivelRendimiento().getDescripcion()));

        System.out.println("=".repeat(80));
    }

    private void mostrarRecomendacionesPrincipales(AnalizadorMetricas.ComparacionMetricas comparacion) {
        System.out.println("\n" + "=".repeat(80));
        System.out.println("üí° RECOMENDACIONES PRINCIPALES");
        System.out.println("=".repeat(80));

        List<String> recomendaciones = generarRecomendaciones(comparacion);

        for (int i = 0; i < recomendaciones.size(); i++) {
            System.out.println((i + 1) + ". " + recomendaciones.get(i));
        }

        System.out.println("\n" + "=".repeat(80));
    }

    private List<String> generarRecomendaciones(AnalizadorMetricas.ComparacionMetricas comparacion) {
        List<String> recomendaciones = new ArrayList<>();

        if (comparacion.getMetricas().isEmpty()) {
            recomendaciones.add("üìä Ejecutar pruebas de rendimiento JMeter para obtener m√©tricas reales");
            recomendaciones.add("üîß Configurar escenarios de prueba con diferentes cargas de usuarios");
            recomendaciones.add("üìà Establecer umbrales de rendimiento para monitoreo continuo");
            return recomendaciones;
        }

        // Analizar m√©tricas reales
        long metricasCriticas = comparacion.getMetricas().stream()
                .filter(m -> m.evaluarNivelRendimiento() == MetricaRendimiento.NivelRendimiento.MALO ||
                        m.evaluarNivelRendimiento() == MetricaRendimiento.NivelRendimiento.INACEPTABLE)
                .count();

        double tiempoPromedio = comparacion.getMetricas().stream()
                .mapToDouble(MetricaRendimiento::getTiempoPromedioMs)
                .average().orElse(0.0);

        double throughputPromedio = comparacion.getMetricas().stream()
                .mapToDouble(MetricaRendimiento::getThroughputReqSeg)
                .average().orElse(0.0);

        if (metricasCriticas > 0) {
            recomendaciones.add("‚ö†Ô∏è Optimizar rendimiento: Se detectaron " + metricasCriticas +
                    " escenarios con rendimiento cr√≠tico que requieren atenci√≥n inmediata.");
        }

        if (tiempoPromedio > 2000) {
            recomendaciones.add("üöÄ Reducir latencia: El tiempo promedio de " +
                    String.format("%.0f ms", tiempoPromedio) +
                    " excede los umbrales recomendados. Implementar cache y optimizar consultas.");
        }

        if (throughputPromedio < 20) {
            recomendaciones.add("üìà Mejorar throughput: El rendimiento actual de " +
                    String.format("%.1f req/s", throughputPromedio) +
                    " puede mejorarse con auto-scaling y balanceador de carga.");
        }

        if (recomendaciones.isEmpty()) {
            recomendaciones.add("‚úÖ Rendimiento aceptable: El sistema muestra m√©tricas dentro de rangos aceptables. " +
                    "Continuar con monitoreo regular.");
            recomendaciones.add("üîÑ Ejecutar pruebas peri√≥dicas para mantener el nivel de calidad");
            recomendaciones.add("üìä Configurar alertas autom√°ticas para degradaci√≥n de rendimiento");
        }

        return recomendaciones;
    }

    /**
     * M√©todo para ejecutar solo an√°lisis sin reportes (para debugging)
     */
    public static void ejecutarSoloAnalisis() {
        try {
            System.out.println("üîç Ejecutando an√°lisis b√°sico de m√©tricas...");

            EjecutorAnalisisMetricas ejecutor = new EjecutorAnalisisMetricas();
            ConfiguracionAplicacion config = ConfiguracionAplicacion.obtenerInstancia();

            AnalizadorMetricas analizador = new AnalizadorMetricas();
            List<MetricaRendimiento> metricas = ejecutor.procesarArchivosJTL(
                    config.obtenerDirectorioResultados(), analizador);

            if (!metricas.isEmpty()) {
                ejecutor.mostrarResumenEnConsola(metricas);
                System.out.println("‚úÖ An√°lisis b√°sico completado");
            } else {
                System.out.println("‚ÑπÔ∏è No se encontraron m√©tricas para analizar");
            }

        } catch (Exception e) {
            System.err.println("‚ùå Error en an√°lisis: " + e.getMessage());
        }
    }
}